{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWCIKmTo1FaA"
      },
      "source": [
        "## **Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UYnhpNlj1FaE"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF, DotProduct\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from imblearn.combine import SMOTETomek # because our data is unbalanced\n",
        "\n",
        "random_state = 42\n",
        "np.random.seed(random_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFocurx_1FaG"
      },
      "source": [
        "## **Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNQloHvy1vA5",
        "outputId": "72a9ea56-00d6-48a3-cb65-7ece805516e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWiQZfX91FaG"
      },
      "outputs": [],
      "source": [
        "dat_nurse = pd.read_csv('./prepared_1061.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1TQCdIt1FaJ"
      },
      "outputs": [],
      "source": [
        "# drop na (outcome na)\n",
        "dat_nurse = dat_nurse[dat_nurse['outcome'].notnull()]\n",
        "# train-test-split\n",
        "train_dat, test_dat = train_test_split(dat_nurse, test_size = 0.15,  stratify=dat_nurse['outcome'], random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8WH_VyW1FaJ"
      },
      "outputs": [],
      "source": [
        "# organizing data\n",
        "outcome_col = train_dat.columns[3]\n",
        "text_col = train_dat.columns[-8:]\n",
        "\n",
        "train_dat_outcome, test_dat_outcome = train_dat.loc[:, outcome_col], test_dat.loc[:, outcome_col]\n",
        "train_dat_text, test_dat_text = train_dat.loc[:, text_col], test_dat.loc[:, text_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrUjs4dz1FaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534dd266-3dc8-465c-ccae-b544cfe8aeaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/val/test shape:  (901, 7926) (159, 7926)\n"
          ]
        }
      ],
      "source": [
        "train_y = train_dat_outcome.to_numpy()\n",
        "test_y = test_dat_outcome.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ygTs2A1FaT"
      },
      "source": [
        "## **Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HfS2Db8H1FaW"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'LogisticRegressionCV' : {\n",
        "        'penalty' : ['l2']\n",
        "    },\n",
        "    'SVC' : {\n",
        "        'kernel' : ['linear', 'poly', 'rbf'],\n",
        "        'degree' : [3, 4, 5]\n",
        "    },\n",
        "    'GaussianProcessClassifier' : { # https://stackoverflow.com/questions/62755556/gaussian-process-regression-hyparameter-optimisation-using-python-grid-search\n",
        "            \"kernel\": [RBF(l) for l in np.logspace(-1, 1, 20)]\n",
        "        },\n",
        "    'XGBClassifier' : { # got from some towardsdatascience article i forgot\n",
        "            'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
        "            'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
        "            'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
        "            'n_estimators': [50,65,80,100,115,130,150],\n",
        "            'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
        "            'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
        "            'eval_metric': ['auc'],\n",
        "            'objective': ['binary:logistic']\n",
        "    },\n",
        "    'RandomForestClassifier': {\n",
        "        'n_estimators': [100],\n",
        "        'min_samples_split': [2],\n",
        "        'min_samples_leaf': [2],\n",
        "        'max_depth': [30],\n",
        "        'class_weight': ['balanced'],\n",
        "        'bootstrap': [False]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dE7gffcX1FaX"
      },
      "outputs": [],
      "source": [
        "def fit(x, y, parameters, n_iter, random_state = 42):\n",
        "    \"\"\"\n",
        "    Randomized hyperparameter tuning for fitting models\n",
        "\n",
        "    parameters:\n",
        "        n_iter -- number of parameter settings sampled\n",
        "    \"\"\"\n",
        "    print(\"Training LogisticRegressionCV:\")\n",
        "    lr = LogisticRegressionCV(max_iter = int(1e6))\n",
        "    rs_lr = RandomizedSearchCV(lr, parameters['LogisticRegressionCV'], n_iter = n_iter, random_state=random_state)\n",
        "    rs_lr.fit(x, y) \n",
        "\n",
        "    print(\"Training SVC:\")\n",
        "    svc = SVC(probability = True)\n",
        "    rs_svc = RandomizedSearchCV(svc, parameters['SVC'], n_iter = n_iter, random_state=random_state)\n",
        "    rs_svc.fit(x, y)\n",
        "\n",
        "    print(\"Training GaussianProcessClassifier:\")\n",
        "    gp = GaussianProcessClassifier()\n",
        "    rs_gp = RandomizedSearchCV(gp, parameters['GaussianProcessClassifier'], n_iter = n_iter, random_state=random_state)\n",
        "    rs_gp.fit(x, y)\n",
        "\n",
        "    print(\"Training XGBClassifier:\")\n",
        "    xgb = XGBClassifier()\n",
        "    rs_xgb = RandomizedSearchCV(xgb, parameters['XGBClassifier'], n_iter = n_iter, random_state=random_state)\n",
        "    rs_xgb.fit(x, y) \n",
        "\n",
        "    print(\"Training Random Forest:\")\n",
        "    rf = RandomForestClassifier()\n",
        "    rs_rf = RandomizedSearchCV(rf, parameters['RandomForestClassifier'], n_iter = n_iter, random_state=random_state)\n",
        "    rs_rf.fit(x, y) \n",
        "\n",
        "    models = [rs_lr, rs_svc, rs_gp, rs_xgb, rs_rf]\n",
        "    return models \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hX-JYbMT1Faa"
      },
      "outputs": [],
      "source": [
        "def evaluate(x, y, models):\n",
        "    scores = {\n",
        "        'ACC': [], \n",
        "        'AUC': [],\n",
        "        'CMAT': []\n",
        "    }\n",
        "    for model in models:\n",
        "        y_pred = model.predict(x)\n",
        "        y_proba = model.predict_proba(x)[:, 1]\n",
        "        scores['ACC'].append(accuracy_score(y, y_pred))\n",
        "        scores['AUC'].append(roc_auc_score(y, y_proba))\n",
        "        scores['CMAT'].append(confusion_matrix(y, y_pred))\n",
        "        \n",
        "    return scores "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr1sy6sV1Fac",
        "outputId": "ef1d3250-e3b6-43a7-95ab-1d07a82d9bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ACC': [0.84375, 0.8541666666666666, 0.8541666666666666, 0.84375],\n",
              " 'AUC': [0.7020905923344947,\n",
              "  0.7168989547038327,\n",
              "  0.7134146341463414,\n",
              "  0.6114982578397212],\n",
              " 'CMAT': [array([[81,  1],\n",
              "         [14,  0]]),\n",
              "  array([[82,  0],\n",
              "         [14,  0]]),\n",
              "  array([[82,  0],\n",
              "         [14,  0]]),\n",
              "  array([[81,  1],\n",
              "         [14,  0]])]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "evaluate(test_x, test_y, models)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **word2vec (w/o imbalance handling)**"
      ],
      "metadata": {
        "id": "j2yiyZ9_DsSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "KEJHpg22-Go9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_processed_text = train_dat['TEXT'].apply(simple_preprocess)"
      ],
      "metadata": {
        "id": "3ajThCS3Eguq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = Word2Vec(sentences = train_processed_text, vector_size = 200, window = 5, min_count = 1)"
      ],
      "metadata": {
        "id": "8_jPNPkiF6VE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def document_vector(doc, model):\n",
        "    doc_vector = []\n",
        "    num_words = 0\n",
        "    for word in doc:\n",
        "        if word in model.wv:\n",
        "            doc_vector.append(model.wv[word])\n",
        "            num_words += 1\n",
        "    if num_words > 0:\n",
        "        doc_vector = np.mean(doc_vector, axis=0)\n",
        "    else:\n",
        "        doc_vector = np.zeros(model.vector_size)\n",
        "    return doc_vector"
      ],
      "metadata": {
        "id": "Zw0aMMBpHaRk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_word2vec_repr = train_processed_text.apply(lambda x: document_vector(x, word2vec_model))"
      ],
      "metadata": {
        "id": "11ZPICrCH8RY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_repr = np.vstack(train_word2vec_repr)"
      ],
      "metadata": {
        "id": "w2t6sKcFIJMe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_models = fit(train_repr, train_y, params, n_iter = 20, random_state = random_state)"
      ],
      "metadata": {
        "id": "PcYvZdf-J921"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in word2vec_models:\n",
        "    print(model.best_estimator_, model.best_params_, model.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCmwRODrKIDZ",
        "outputId": "304949a2-67d8-414e-9128-656796215c28"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegressionCV(max_iter=1000000) {'penalty': 'l2'} 0.8690362185389808\n",
            "SVC(kernel='linear', probability=True) {'kernel': 'linear', 'degree': 3} 0.8690362185389808\n",
            "GaussianProcessClassifier(kernel=RBF(length_scale=0.1)) {'kernel': RBF(length_scale=0.1)} 0.8690362185389808\n",
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
            "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.6, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
            "              predictor=None, random_state=None, ...) {'reg_lambda': 1.6, 'reg_alpha': 12.8, 'objective': 'binary:logistic', 'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.6, 'gamma': 0, 'eval_metric': 'auc'} 0.8690362185389808\n",
            "RandomForestClassifier(bootstrap=False, class_weight='balanced', max_depth=30,\n",
            "                       min_samples_leaf=2) {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30, 'class_weight': 'balanced', 'bootstrap': False} 0.8634929404542664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_processed_text = test_dat['TEXT'].apply(simple_preprocess)\n",
        "test_word2vec_repr = test_processed_text.apply(lambda x: document_vector(x, word2vec_model))\n",
        "test_repr = np.vstack(test_word2vec_repr)"
      ],
      "metadata": {
        "id": "SIWyBg0MTELT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_repr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxTyY5_H0chQ",
        "outputId": "879ea7ec-424a-4230-aa33-986f11d96684"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_repr, test_y, word2vec_models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ-zFNG5U-0B",
        "outputId": "33e8560d-5165-4152-9113-17b487a9d23b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ACC': [0.8679245283018868,\n",
              "  0.8679245283018868,\n",
              "  0.8679245283018868,\n",
              "  0.8679245283018868,\n",
              "  0.8742138364779874],\n",
              " 'AUC': [0.5013802622498275,\n",
              "  0.5100069013112492,\n",
              "  0.4998274672187716,\n",
              "  0.5833333333333334,\n",
              "  0.5628019323671497],\n",
              " 'CMAT': [array([[138,   0],\n",
              "         [ 21,   0]]),\n",
              "  array([[138,   0],\n",
              "         [ 21,   0]]),\n",
              "  array([[138,   0],\n",
              "         [ 21,   0]]),\n",
              "  array([[138,   0],\n",
              "         [ 21,   0]]),\n",
              "  array([[138,   0],\n",
              "         [ 20,   1]])]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **word2vec (w/ Imbalance Handling)**"
      ],
      "metadata": {
        "id": "H5wd8MjndsuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "ptE6Ctempbp4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "under_sampling_strategy = 0.2\n",
        "over_sampling_strategy = 1.0\n",
        "\n",
        "resampling_pipeline = Pipeline([\n",
        "    ('under', RandomUnderSampler(sampling_strategy=under_sampling_strategy)),\n",
        "    ('over', RandomOverSampler(sampling_strategy=over_sampling_strategy))\n",
        "])"
      ],
      "metadata": {
        "id": "3Z3Iu8aZpe9X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_repr_resamp, train_y_resamp = resampling_pipeline.fit_resample(np.array(train_repr), np.array(train_y))"
      ],
      "metadata": {
        "id": "6UX0dAcFprR0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_models_oversamp = fit(train_repr_resamp, train_y_resamp, params, n_iter = 30, random_state = random_state)"
      ],
      "metadata": {
        "id": "wnXHFZkMoEJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_repr, test_y, word2vec_models_oversamp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0aVLOUjBjp",
        "outputId": "37682a2f-51a9-4398-dccb-c49d5be75f49"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ACC': [0.5849056603773585,\n",
              "  0.42138364779874216,\n",
              "  0.8679245283018868,\n",
              "  0.8050314465408805,\n",
              "  0.8553459119496856],\n",
              " 'AUC': [0.5255348516218081,\n",
              "  0.5227743271221532,\n",
              "  0.5,\n",
              "  0.5800552104899931,\n",
              "  0.5407177363699103],\n",
              " 'CMAT': [array([[88, 50],\n",
              "         [16,  5]]),\n",
              "  array([[53, 85],\n",
              "         [ 7, 14]]),\n",
              "  array([[138,   0],\n",
              "         [ 21,   0]]),\n",
              "  array([[126,  12],\n",
              "         [ 19,   2]]),\n",
              "  array([[136,   2],\n",
              "         [ 21,   0]])]}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### try penalization"
      ],
      "metadata": {
        "id": "d5Wx-zGStI_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer, confusion_matrix\n",
        "\n",
        "def custom_scorer(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    # Adjust the weight according to your preference\n",
        "    false_negative_weight = 5\n",
        "    \n",
        "    score = tp - false_negative_weight * fn\n",
        "    return score\n",
        "  \n",
        "custom_scorer = make_scorer(custom_scorer, greater_is_better=True)"
      ],
      "metadata": {
        "id": "MTj8ZuL3t9Qg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_penalized(x, y, parameters, n_iter, random_state = 42):\n",
        "    print(\"Training GaussianProcessClassifier:\")\n",
        "    gp = GaussianProcessClassifier()\n",
        "    rs_gp = RandomizedSearchCV(gp, parameters['GaussianProcessClassifier'], n_iter = n_iter, random_state=random_state, scoring=custom_scorer)\n",
        "    rs_gp.fit(x, y)\n",
        "\n",
        "    print(\"Training XGBClassifier:\")\n",
        "    xgb = XGBClassifier()\n",
        "    parameters['XGBClassifier']['scale_pos_weight'] = [5] \n",
        "    rs_xgb = RandomizedSearchCV(xgb, parameters['XGBClassifier'], n_iter = n_iter, random_state=random_state)\n",
        "    rs_xgb.fit(x, y) \n",
        "\n",
        "    models = [rs_gp, rs_xgb]\n",
        "    return models "
      ],
      "metadata": {
        "id": "ktQvZkA8tXc0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_models_penal = fit_penalized(train_repr_resamp, train_y_resamp, params, n_iter = 30, random_state = random_state)"
      ],
      "metadata": {
        "id": "lL8JNj1etSfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_repr, test_y, word2vec_models_penal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUcbnQL4uuF1",
        "outputId": "96226bc0-f3eb-43c3-a247-d4fb6b9cd222"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ACC': [0.8679245283018868, 0.7672955974842768],\n",
              " 'AUC': [0.5, 0.48895790200138023],\n",
              " 'CMAT': [array([[138,   0],\n",
              "         [ 21,   0]]),\n",
              "  array([[121,  17],\n",
              "         [ 20,   1]])]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bst263_final",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}